# Compact print & sorted
jq -cS .

# Original jq since mine is aliased w/ color
\jq .

# Create new json from existing json
cat package.json | jq '. | {dep: .dependencies, devDep: .devDependencies}' | egrep -v "\{|\}" | sort

# Count length (either number of records in a hash or in an array
jq '. | length'

# Filter on field in object
time cat <file> |  \jq -cS '. | select(.originLogType == "sourcetInviteToApply")' > ,output

# Slice & Dice
jq '.[2:4]'
jq '.[:3]'
jq '.[-2:]'

# List keys of a json object
jq '.jobs[0] | keys'


# Sort by key and list only keys
cat <file> | jq '.jobs|=sort_by(.company) | .jobs[].company' | less

# Sort all keys
cat ,app_557345 | jq -S .SparkProperties | less

# Get min, max, average & median of a list of numbers
cat emr-cluster-service.log | grep SparkEnv | awk -F "SparkEnvMetrics: " '{print $2}' | transpose-log-entries | grep timeElasped | cut -d= -f2 | jq -s '{minimum:min,maximum:max,average:(add/length),median:(sort|if length%2==1 then.[length/2|floor]else[.[length/2-1,length/2]]|add/2 end)}'

